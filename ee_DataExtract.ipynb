{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "####################################################\n",
    "# CODE TO EXTRACT DATA FROM GEE IMAGE COLLECTIONS\n",
    "# \n",
    "# INPUTS: PYTHON GEE ENVIRONMENT\n",
    "#         GEE ACCOUNT AND LOGIN INFO  \n",
    "#         geojason files as AOI\n",
    "#\n",
    "# DATE:   Jun 20, 2021\n",
    "# Author: VIKALP MISHRA\n",
    "#         SERVIR SCO\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import os, glob, sys\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate and initialize GEE login \n",
    "\n",
    "(If you get 'oauth2client' error, try installing an older version of the package e.g. pip install oauth2client==3.0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    #function to loop through weeks\n",
    "    for n in range(0,int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Cloud mask for pixels with less than 20% cloud cover \n",
    "    # Compute the bits we need to extract.\n",
    "    # Return a single band image of the extracted QA bits, giving the band a new name.\n",
    "    pattern = 0\n",
    "    for i in range(start,end-1):\n",
    "        pattern += 2**i\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "        \n",
    "def maskS2clouds(image):\n",
    "    #Return the masked and scaled Sentinal2 data, without the QA bands\n",
    "    #Bits 10 and 11 are clouds and cirrus, respectively\n",
    "    qa = image.select('QA60')\n",
    "    cloudBitMask = getQABits(qa,10,10,'cloud')\n",
    "    cirrusBitMask = getQABits(qa,11,11,'cirrus')\n",
    "    return image.updateMask(cloudBitMask.eq(0).updateMask(cirrusBitMask.eq(0))).divide(10000).select(\"B.*\").float().copyProperties(image, [\"system:time_start\", \"system:index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskL8clouds(image):\n",
    "    #Return the masked and scaled Landsat8 data, without the QA bands\n",
    "    # Bits 3 and 5 are cloud shadow and cloud, respectively\n",
    "    qa = image.select('pixel_qa')\n",
    "    cloudShadowBitMask = getQABits(qa,3,3,'cloud_shadow')\n",
    "    cloudBitMask = getQABits(qa,5,5,'cloud')\n",
    "    cirrusBitMask = getQABits(qa,9,9,'cirrus')\n",
    "    return image.updateMask(cloudShadowBitMask.eq(0)).updateMask(cloudBitMask.eq(0).updateMask(cirrusBitMask.eq(0))).divide(10000).select(\"B[0-9]*\").float().copyProperties(image, [\"system:time_start\", \"system:index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskL57clouds(image):\n",
    "    # Return the masked image, scaled to reflectance, without the QA bands\n",
    "    # Bits 1,2 and 3 are cloud shadow and cloud, respectively\n",
    "    qa = image.select('sr_cloud_qa')\n",
    "    cloudShadowBitMask = getQABits(qa,2,2,'cloud_shadow')\n",
    "    cloudBitMask = getQABits(qa,1,1,'cloud')\n",
    "    cirrusBitMask = getQABits(qa,3,3,'cirrus')\n",
    "    return image.updateMask(cloudShadowBitMask.eq(0)).updateMask(cloudBitMask.eq(0).updateMask(cirrusBitMask.eq(0))).divide(10000).select(\"B[0-9]*\").float().copyProperties(image, [\"system:time_start\", \"system:index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNDVI_l8(image):\n",
    "    # compute NDVI for Landsat 8\n",
    "    ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNDVI_s2(image):\n",
    "    # compute NDVI for Sentinal 2\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNDVI_l57(image):\n",
    "    # compute NDVI for Landsat 5-7\n",
    "    ndvi = image.normalizedDifference(['B4', 'B3']).rename('NDVI')\n",
    "    return image.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce_region(image):\n",
    "    # Spatial aggregation function for a single image and a polygon feature\n",
    "    # FEature needs to be rebuilt because the backend doesn't accept to map\n",
    "    # functions that return dictionaries\n",
    "    size = 30\n",
    "    fnc = ee.Reducer.mean()\n",
    "    stat_dict = image.reduceRegion(fnc, geom, size);\n",
    "    return ee.Feature(None, stat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(fc):\n",
    "    def feature2dict(f):\n",
    "        '''\n",
    "        converting feature to dict user might have to modify identifires\n",
    "        to correctly link to specified image collection - its hard codded in this \n",
    "        case for chirps precip and L7/L8 datasets \n",
    "        '''\n",
    "        \n",
    "        tmp = None\n",
    "        if 'precip' in list(fc['features'][0]['properties'].keys())[0]:\n",
    "            tmp = f['id']\n",
    "        if f['id'][:2] == '1_':\n",
    "            tmp = f['id'].split('_')[3]\n",
    "        if f['id'][:2] == '2_':\n",
    "            tmp = f['id'][2:10]\n",
    "        if f['id'][0] =='L' or f['id'][:2] == '20':\n",
    "            if 'LC' in f['id'] or 'LE' in f['id']:\n",
    "                tmp = f['id'].split('_')[2]\n",
    "            if 'T3' in f['id']:\n",
    "                tmp = f['id'].split('_')[0]\n",
    "                tmp = tmp[:8]\n",
    "        id = tmp\n",
    "        out = f['properties']\n",
    "        out.update(id=id)\n",
    "        return out\n",
    "    out = [feature2dict(x) for x in fc['features']]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(fc,flag, duration = None):\n",
    "    \"\"\" \n",
    "    function to perform spatial aggregation & extract image collection data\n",
    "    inta a pandas dataframe \n",
    "    \n",
    "    INPUTS:\n",
    "    FC      : feature collection information\n",
    "    Flag    : 1 - Precipitation\n",
    "              0 - NDVI data\n",
    "    duration: M - Monthly statistics\n",
    "              Y - Yearly statistics\n",
    "              \n",
    "    For precipitation total sum is used whereas for NDVI monthly max is used by default\n",
    "    \"\"\"\n",
    "    \n",
    "    sfc = simplify(fc)\n",
    "    a = pd.DataFrame.from_dict(sfc)\n",
    "    a.index = pd.to_datetime(a['id'], infer_datetime_format = True)\n",
    "    a = a.drop('id', axis = 1)\n",
    "    \n",
    "    if flag == 1:   # Precip\n",
    "        if duration == 'M':\n",
    "            a = a.resample('M').sum()\n",
    "        if duration == 'Y':\n",
    "            a = a.resample('Y').sum()   \n",
    "    \n",
    "    if flag == 0:   # NDVI\n",
    "        if duration != None:\n",
    "            if duration == 'M':\n",
    "                a = a.resample('M').max()\n",
    "            if duration == 'Y':\n",
    "                a = a.resample('Y').max()\n",
    "        else:\n",
    "            print('Invalid parameters...exiting now')\n",
    "            sys.exit()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Users/vmishra2/Documents/SERVIR/Misc/Resileience/Niger/\"\n",
    "geojsons = glob.glob(input_dir+\"2*.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 has  27  features\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vmishra2/miniconda3/envs/ee/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "for geojson in geojsons:\n",
    "    fname = geojson.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    with open(geojson,\"r\") as f:\n",
    "        data = f.read()\n",
    "        fc_str = json.loads(data)\n",
    "        \n",
    "        df_ch = pd.DataFrame()\n",
    "        df_l8 = pd.DataFrame()\n",
    "        df_l7 = pd.DataFrame()\n",
    "        df_s2 = pd.DataFrame()\n",
    "        \n",
    "        df_l8['Date'] = pd.date_range('1/1/2002','12/31/2020')\n",
    "        df_l7['Date'] = pd.date_range('1/1/2002','12/31/2020')\n",
    "        df_s2['Date'] = pd.date_range('1/1/2002','12/31/2020')\n",
    "        \n",
    "        df_l8 = df_l8.set_index('Date')\n",
    "        df_l7 = df_l7.set_index('Date')\n",
    "        df_s2 = df_s2.set_index('Date')\n",
    "        \n",
    "        print(str(fname) +' has ', len(fc_str['features']),' features')\n",
    "        for ii in range(len(fc_str['features'])):\n",
    "            aoi_ = fc_str['features'][ii]['geometry']\n",
    "            \n",
    "            name1 = fc_str['features'][ii]['properties']['Name']\n",
    "            name2 = fc_str['features'][ii]['properties']['FID']\n",
    "            name = name1+'_'+str(name2)\n",
    "            \n",
    "            #get base collections and subset to aoi_\n",
    "            l8_boa = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\").filterBounds(aoi_).filterDate('2012-1-1','2020-12-31')\n",
    "            l7_boa = ee.ImageCollection(\"LANDSAT/LE07/C01/T1_SR\").filterBounds(aoi_).filterDate('2002-1-1','2020-12-31')\n",
    "            s2_boa = ee.ImageCollection(\"COPERNICUS/S2_SR\").filterBounds(aoi_).filterDate('2012-1-1','2020-12-31')\n",
    "            precp = ee.ImageCollection(\"UCSB-CHG/CHIRPS/PENTAD\").filterBounds(aoi_).filterDate('2002-1-1','2020-12-31').select('precipitation')\n",
    "            \n",
    "            #maps bands to each other  \n",
    "            bands_l8 = ['B1','B2','B3','B4','B5','B6','B7']   #var bands_l8 = ['B1','B2','B3','B4','B5','B6','B7','QA60'];\n",
    "            bands_s2 = ['B1','B2','B3','B4','B8','B11','B12']   #var bands_s2 = ['B1','B2','B3','B4','B8','B11','B12','QA60'];\n",
    "            \n",
    "            # perform cloud masking\n",
    "            s2_boa_cm = s2_boa.map(maskS2clouds)\n",
    "            l8_boa_cm = l8_boa.map(maskL8clouds)\n",
    "            l7_boa_cm = l7_boa.map(maskL57clouds)\n",
    "            \n",
    "            # get NDVI\n",
    "            l8_ndvi = l8_boa_cm.map(addNDVI_l8).select('NDVI')\n",
    "            l7_ndvi = l7_boa_cm.map(addNDVI_l57).select('NDVI')\n",
    "            s2_ndvi = s2_boa_cm.map(addNDVI_s2).select('NDVI')\n",
    "            \n",
    "            geom = ee.Geometry.MultiPolygon(aoi_[\"coordinates\"])\n",
    "            size = 30\n",
    "            fnc = ee.Reducer.mean()\n",
    "            \n",
    "            # CHIRPS Precip\n",
    "            fc = precp.map(_reduce_region).getInfo()\n",
    "            chirp = compute(fc,1,'M')\n",
    "            chirp.columns = [name]\n",
    "\n",
    "            # L8 NDVI\n",
    "            fc = l8_ndvi.map(_reduce_region).getInfo()\n",
    "            l8vi =  compute(fc,0,'M')\n",
    "            l8vi.columns = [name]\n",
    "            \n",
    "            # L7 NDVI\n",
    "            fc = l7_ndvi.map(_reduce_region).getInfo()\n",
    "            l7vi =  compute(fc,0,'M')\n",
    "            l7vi.columns = [name]\n",
    "            \n",
    "            # S2 NDVI\n",
    "            fc = s2_ndvi.map(_reduce_region).getInfo()\n",
    "            s2vi =  compute(fc,0,'M')\n",
    "            s2vi.columns = [name]\n",
    "\n",
    "            #Store extracted values to pandas dataframe\n",
    "            df_l8 = df_l8.merge(l8vi, left_index=True, right_index=True, how='left')\n",
    "            df_l7 = df_l7.merge(l7vi, left_index=True, right_index=True, how='left')\n",
    "            df_s2 = df_s2.merge(s2vi, left_index=True, right_index=True, how='left')\n",
    "            \n",
    "            if ii == 0:\n",
    "                df_ch = chirp\n",
    "                df_l8 = l8vi\n",
    "                df_l7 = l7vi\n",
    "                df_s2 = s2vi\n",
    "            else:\n",
    "                df_ch = df_ch.merge(chirp, left_index=True, right_index=True, how='left')\n",
    "                df_l8 = df_l8.merge(l8vi, left_index=True, right_index=True, how='left')\n",
    "                df_l7 = df_l7.merge(l7vi, left_index=True, right_index=True, how='left')\n",
    "                df_s2 = df_s2.merge(s2vi, left_index=True, right_index=True, how='left')\n",
    "            sys.exit()\n",
    "            \n",
    "        # save data into csv files\n",
    "        df_ch.to_csv(input_dir+yr+'_chirps.csv')\n",
    "        df_l8.to_csv(input_dir+yr+'_L8.csv')\n",
    "        df_l7.to_csv(input_dir+yr+'_L7.csv')\n",
    "        df_s2.to_csv(input_dir+yr+'_S2.csv')\n",
    "        \n",
    "        \n",
    "sys.exit()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gochiro_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-30</th>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-31</th>\n",
       "      <td>0.136476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.162010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>0.161469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-31</th>\n",
       "      <td>0.248491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gochiro_0\n",
       "id                   \n",
       "2013-04-30   0.005741\n",
       "2013-05-31   0.136476\n",
       "2013-06-30   0.162010\n",
       "2013-07-31   0.161469\n",
       "2013-08-31   0.248491"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_l8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
